{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "#reading the data in\n",
    "test = pd.read_csv('/home/kilian/Desktop/Projects/test.csv')\n",
    "train = pd.read_csv('/home/kilian/Desktop/Projects/train.csv')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train_x is:  (42000, 784) the shape of test_x is:  (28000, 784) \n",
      "the shape of train_y is:  (42000,) \n",
      "\n",
      "the shape of train_X is:  (42000, 28, 28, 1) the shape of test_X is:  \n",
      "the shape of test_Y is: (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "#splitting training set into labels and images\n",
    "train_x, test_x = train.iloc[:,1:].values , test.iloc[:,:].values\n",
    "train_y = train['label']\n",
    "print(\"the shape of train_x is: \" , train_x.shape, \"the shape of test_x is: \", test_x.shape \n",
    "      , \"\\nthe shape of train_y is: \", train_y.shape,\"\\n\")\n",
    "#preprocess\n",
    "train_X, test_X = train_x.reshape(42000,28,28,1) , test_x.reshape(28000,28,28,1)\n",
    "train_Y  = to_categorical(train_y) #'one-hot-encode' the target\n",
    "print(\"the shape of train_X is: \" , train_X.shape, \"the shape of test_X is: \"\n",
    "      , \"\\nthe shape of test_Y is:\", train_Y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split the data into train and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_Y , test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1050/1050 [==============================] - 19s 18ms/step - loss: 0.3878 - accuracy: 0.9355 - val_loss: 0.1342 - val_accuracy: 0.9586\n",
      "Epoch 2/10\n",
      "1050/1050 [==============================] - 19s 18ms/step - loss: 0.0802 - accuracy: 0.9755 - val_loss: 0.1197 - val_accuracy: 0.9606\n",
      "Epoch 3/10\n",
      "1050/1050 [==============================] - 18s 17ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 0.1320 - val_accuracy: 0.9694\n",
      "Epoch 4/10\n",
      "1050/1050 [==============================] - 18s 18ms/step - loss: 0.0392 - accuracy: 0.9873 - val_loss: 0.1208 - val_accuracy: 0.9718\n",
      "Epoch 5/10\n",
      "1050/1050 [==============================] - 18s 17ms/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.1202 - val_accuracy: 0.9751\n",
      "Epoch 6/10\n",
      "1050/1050 [==============================] - 18s 17ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.1765 - val_accuracy: 0.9738\n",
      "Epoch 7/10\n",
      "1050/1050 [==============================] - 18s 18ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.1526 - val_accuracy: 0.9751\n",
      "Epoch 8/10\n",
      "1050/1050 [==============================] - 18s 17ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.1551 - val_accuracy: 0.9763\n",
      "Epoch 9/10\n",
      "1050/1050 [==============================] - 19s 18ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.2232 - val_accuracy: 0.9704\n",
      "Epoch 10/10\n",
      "1050/1050 [==============================] - 19s 18ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.1741 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f85a87eccd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.0900602e-09 1.7277723e-07 5.8054220e-06 6.5065836e-10 3.2704100e-11\n",
      "  3.8742323e-10 5.9790956e-10 1.7162017e-14 9.9999392e-01 1.0141215e-07]\n",
      " [7.1336300e-16 9.9999988e-01 6.4405816e-12 6.3426526e-16 1.0005305e-07\n",
      "  6.5452483e-13 1.6182960e-13 1.3088924e-13 2.7055160e-11 3.5265530e-18]\n",
      " [9.1641655e-10 2.6208344e-10 2.4277793e-11 8.5693784e-05 5.7206064e-05\n",
      "  4.9933265e-06 8.9215866e-14 1.4509640e-04 1.2503856e-08 9.9970692e-01]\n",
      " [1.0615492e-11 7.3148455e-17 8.3054792e-11 1.0041188e-05 2.8701661e-05\n",
      "  2.8676965e-08 2.3049740e-13 3.8610894e-02 1.8928965e-07 9.6135008e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict first 4 images in the test set\n",
    "print(model.predict(X_test[:4]))\n",
    "\n",
    "#actual results for first 4 images in test set\n",
    "y_test[:4]\n",
    "\n",
    "#visualize the first 4 images\n",
    "# show images\n",
    "X_test_r = X_test.reshape(8400,28,28)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(X_test_r[0], cmap='gray')\n",
    "plt.title('')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(X_test_r[1], cmap='gray')\n",
    "plt.title('')\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(X_test_r[2], cmap='gray')\n",
    "plt.title('')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(X_test_r[3], cmap='gray')\n",
    "plt.title('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1050/1050 [==============================] - 37s 36ms/step - loss: 0.2239 - accuracy: 0.9438 - val_loss: 0.0898 - val_accuracy: 0.9727\n",
      "Epoch 2/3\n",
      "1050/1050 [==============================] - 37s 35ms/step - loss: 0.0642 - accuracy: 0.9804 - val_loss: 0.0771 - val_accuracy: 0.9770\n",
      "Epoch 3/3\n",
      "1050/1050 [==============================] - 37s 36ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.0959 - val_accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f865155c610>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1050/1050 [==============================] - 49s 47ms/step - loss: 0.1835 - categorical_accuracy: 0.9503 - accuracy: 0.9503 - val_loss: 0.0760 - val_categorical_accuracy: 0.9770 - val_accuracy: 0.9770\n",
      "Epoch 2/10\n",
      "1050/1050 [==============================] - 49s 47ms/step - loss: 0.0638 - categorical_accuracy: 0.9806 - accuracy: 0.9806 - val_loss: 0.0802 - val_categorical_accuracy: 0.9769 - val_accuracy: 0.9769\n",
      "Epoch 3/10\n",
      "1050/1050 [==============================] - 50s 47ms/step - loss: 0.0486 - categorical_accuracy: 0.9841 - accuracy: 0.9841 - val_loss: 0.0928 - val_categorical_accuracy: 0.9724 - val_accuracy: 0.9724\n",
      "Epoch 4/10\n",
      "1050/1050 [==============================] - 50s 48ms/step - loss: 0.0363 - categorical_accuracy: 0.9884 - accuracy: 0.9884 - val_loss: 0.0693 - val_categorical_accuracy: 0.9808 - val_accuracy: 0.9808\n",
      "Epoch 5/10\n",
      "1050/1050 [==============================] - 49s 47ms/step - loss: 0.0315 - categorical_accuracy: 0.9896 - accuracy: 0.9896 - val_loss: 0.0906 - val_categorical_accuracy: 0.9783 - val_accuracy: 0.9783\n",
      "Epoch 6/10\n",
      "1050/1050 [==============================] - 50s 47ms/step - loss: 0.0255 - categorical_accuracy: 0.9914 - accuracy: 0.9914 - val_loss: 0.0912 - val_categorical_accuracy: 0.9795 - val_accuracy: 0.9795\n",
      "Epoch 7/10\n",
      "1050/1050 [==============================] - 50s 48ms/step - loss: 0.0234 - categorical_accuracy: 0.9923 - accuracy: 0.9923 - val_loss: 0.0895 - val_categorical_accuracy: 0.9795 - val_accuracy: 0.9795\n",
      "Epoch 8/10\n",
      "1050/1050 [==============================] - 50s 47ms/step - loss: 0.0212 - categorical_accuracy: 0.9939 - accuracy: 0.9939 - val_loss: 0.1043 - val_categorical_accuracy: 0.9782 - val_accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "1050/1050 [==============================] - 50s 48ms/step - loss: 0.0177 - categorical_accuracy: 0.9943 - accuracy: 0.9943 - val_loss: 0.1171 - val_categorical_accuracy: 0.9749 - val_accuracy: 0.9749\n",
      "Epoch 10/10\n",
      "1050/1050 [==============================] - 50s 48ms/step - loss: 0.0203 - categorical_accuracy: 0.9940 - accuracy: 0.9940 - val_loss: 0.1287 - val_categorical_accuracy: 0.9736 - val_accuracy: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f59ec479310>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='CategoricalAccuracy')\n",
    "\n",
    "#train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
